{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "349b4a00",
      "metadata": {},
      "source": [
        "# Deploy Nemotron Super 49B to Vertex Model Garden\n",
        "This notebook demonstrates how to deploy Llama Nemotron NVIDIA Inference Microservices (NIM) to Google Cloud Platform (GCP) Vertex AI Model Garden."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8123068e",
      "metadata": {},
      "source": [
        "## Use Case\n",
        "Developers designing AI Agent systems, chatbots, RAG systems, and other AI-powered applications. Also suitable for typical instruction-following tasks.\n",
        "\n",
        "For more information please refer to this [documentation](https://www.nvidia.com/en-us/ai-data-science/foundation-models/nemotron/) and [build.nvidia.com](https://build.nvidia.com/nvidia/llama-3_3-nemotron-super-49b-v1_5/modelcard)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62ae3235",
      "metadata": {},
      "source": [
        "## 1. Enable model in Vertex Model Garden"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fe0f1f6",
      "metadata": {},
      "source": [
        "Please go to [Vertex Model Garden](https://console.cloud.google.com/vertex-ai/publishers/nvidia/model-garden/llama-nemotron-super), click `Enable` and follow the prompts."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ce80616",
      "metadata": {},
      "source": [
        "## 2. Authenticate and install dependencies\n",
        "\n",
        "Run the following command in the terminal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbf9fec9",
      "metadata": {},
      "outputs": [],
      "source": [
        "! gcloud auth application-default login"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d79dc8c",
      "metadata": {},
      "source": [
        "Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65902c80",
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install --upgrade --force-reinstall \"google-cloud-aiplatform>=1.135.0\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3848d64",
      "metadata": {},
      "source": [
        "## 3. Initialize clients"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6e216b4",
      "metadata": {},
      "source": [
        "Set the following variables accordingly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db47659d",
      "metadata": {},
      "outputs": [],
      "source": [
        "PROJECT_ID = \"your-project-id\"\n",
        "REGION = \"us-central1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ccac166",
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_ID = \"nvidia/llama-nemotron-super@49b\"\n",
        "MODEL_NAME = \"nvidia/llama-3.3-nemotron-super-49b-v1.5\"\n",
        "ENDPOINT_NAME = \"nvidia-llama-nemotron-super-49b\"\n",
        "\n",
        "import json\n",
        "import vertexai\n",
        "from vertexai import model_garden\n",
        "from google.cloud import aiplatform\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "486b9d3d",
      "metadata": {},
      "source": [
        "## 4. Deploy the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df21c9d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = model_garden.OpenModel(MODEL_ID)\n",
        "\n",
        "endpoint = model.deploy(\n",
        "    machine_type=\"g4-standard-384\",\n",
        "    accelerator_type=\"NVIDIA_RTX_PRO_6000\",\n",
        "    accelerator_count=8,\n",
        "    accept_eula=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "508e7d64",
      "metadata": {},
      "source": [
        "## 5. List model endpoints and filter for endpoint name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b240a984",
      "metadata": {},
      "outputs": [],
      "source": [
        "endpoints = aiplatform.Endpoint.list()\n",
        "target = next((ep for ep in endpoints if ENDPOINT_NAME in ep.display_name), None)\n",
        "assert target, f\"Endpoint containing {ENDPOINT_NAME} not found\"\n",
        "target"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c84a9399",
      "metadata": {},
      "source": [
        "## 6. Perform inference against the filtered endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d93c458",
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = \"Give one fact about Vertex AI.\"\n",
        "body = json.dumps(\n",
        "    {\n",
        "        \"model\": MODEL_NAME,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "        \"max_tokens\": 64,\n",
        "    }\n",
        ").encode(\"utf-8\")\n",
        "\n",
        "response = target.raw_predict(\n",
        "    body=body,\n",
        "    headers={\"Content-Type\": \"application/json\"},\n",
        "    use_dedicated_endpoint=True,\n",
        ")\n",
        "\n",
        "assert response.status_code == 200, response.text\n",
        "payload = response.json()\n",
        "print(payload)\n",
        "\n",
        "print(payload[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f4d5af6",
      "metadata": {},
      "source": [
        "## 7. Cleanup\n",
        "Run only if you want to remove the deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85749226",
      "metadata": {},
      "outputs": [],
      "source": [
        "endpoints = aiplatform.Endpoint.list()\n",
        "target = next((ep for ep in endpoints if ENDPOINT_NAME in ep.display_name), None)\n",
        "target.undeploy_all()\n",
        "target.delete()"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
