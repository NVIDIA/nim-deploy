apiVersion: blueprints.cloud.google.com/v1alpha1
kind: BlueprintMetadata
metadata:
  name: nim-on-gke-display
  annotations:
    config.kubernetes.io/local-config: "true"
spec:
  info:
    title: NVIDIA NIM on GKE
    source:
      repo: https://github.com/NVIDIA/nim-deploy
      sourceType: git
      dir: /cloud-service-providers/google-cloud/gke
  ui:
    input:
      variables:
        acknowledge:
          name: acknowledge
          title: Check to confirm you enabled Google APIs for your project with this command.
          section: acknowledge
          subtext: |
                  <pre>
                    <code style="background: #f4f4f4;border: 1px solid #ddd; border-left: 3px solid #3367d6; color: #6d6868; font-size: 12px; max-width: 100%; padding: 0.5em 0.5em; display: inline; line-height: 45px;">gcloud services enable serviceusage.googleapis.com cloudresourcemanager.googleapis.com</code>
                  </pre>
          enumValueLabels:
            - label: Confirm that all prerequisites have been met.
              value: "true"
        additional_labels:
          name: additional_labels
          title: Additional Labels
          invisible: true
          section: required_config
        #cluster_location:
        #  name: cluster_location
        #  title: Cluster Location
        #  section: required_config
        #  xGoogleProperty:
        #    type: ET_GCE_REGION
        #    # specified regions have L4, A2 and A3 GPUs https://cloud.google.com/compute/docs/gpus/gpu-regions-zones#view-using-tools
        #    gce_region:
        #      allowlisted_regions: ["asia-east1","asia-southeast1","europe-west1","europe-west4","us-central1","us-east1","us-east4","us-west1","us-west4"]
        cluster_name:
          name: cluster_name
          title: Cluster Name
          section: required_config
        create_network:
          name: create_network
          title: Create Network
          invisible: true
        enable_gpu:
          name: enable_gpu
          title: Enable GPU nodepool
          section: required_config
          invisible: true
        goog_cm_deployment_name:
          name: goog_cm_deployment_name
          title: Goog CM Deployment Name         
        kubernetes_namespace:
          name: kubernetes_namespace
          title: Kubernetes Namespace
          section: required_config
          invisible: true
        network_name:
          name: network_name
          title: Network Name
          section: required_config
          invisible: true
        project_id:
          name: project_id
          title: Project Id
          invisible: true
        subnetwork_cidr:
          name: subnetwork_cidr
          title: SubNetwork CIDR
          invisible: true
        subnetwork_name:
          name: subnetwork_name
          title: SubNetwork Name
          invisible: true
        ngc_username:
          name: ngc_username
          title: NGC Login username
          section: required_config
          invisible: true
        ngc_api_key:
          name: ngc_api_key
          title: NGC API Key
          section: required_config
          invisible: true
        registry_server:
          name: registry_server
          title: NVIDIA Registry
          section: required_config
          invisible: true
        tag:
          name: tag
          title: NIM image tag
          section: required_config
          invisible: true     
        region_based_vm:
          name: region_based_vm
          title: Cluster and GPU location
          section: required_config
          enumValueLabels:
            - label: "L4 asia-east1 g2-standard-24"
              value: "L4 asia-east1 g2-standard-24"
            - label: "L4 asia-south1 g2-standard-24"
              value: "L4 asia-south1 g2-standard-24"
            - label: "L4 europe-west1 g2-standard-24"
              value: "L4 europe-west1 g2-standard-24"
            - label: "L4 us-central1 g2-standard-24" 
              value: "L4 us-central1 g2-standard-24"
            - label: "L4 us-east4 g2-standard-24"
              value: "L4 us-east4 g2-standard-24"
            - label: "L4 us-west1 g2-standard-24" 
              value: "L4 us-west1 g2-standard-24"
            - label: "L4 asia-east1 g2-standard-48"
              value: "L4 asia-east1 g2-standard-48"
            - label: "L4 asia-south1 g2-standard-48"
              value: "L4 asia-south1 g2-standard-48"
            - label: "L4 europe-west1 g2-standard-48"
              value: "L4 europe-west1 g2-standard-48"
            - label: "L4 us-central1 g2-standard-48"
              value: "L4 us-central1 g2-standard-48"
            - label: "L4 us-east4 g2-standard-48"
              value: "L4 us-east4 g2-standard-48"
            - label: "L4 us-west1 g2-standard-48"
              value: "L4 us-west1 g2-standard-48"
            - label: "L4 asia-east1 g2-standard-96"
              value: "L4 asia-east1 g2-standard-96"
            - label: "L4 asia-south1 g2-standard-96"
              value: "L4 asia-south1 g2-standard-96"
            - label: "L4 europe-west1 g2-standard-96"
              value: "L4 europe-west1 g2-standard-96"
            - label: "L4 us-central1 g2-standard-96"
              value: "L4 us-central1 g2-standard-96"
            - label: "L4 us-east4 g2-standard-96"
              value: "L4 us-east4 g2-standard-96"
            - label: "L4 us-west1 g2-standard-96"
              value: "L4 us-west1 g2-standard-96"
            - label: "H100(80GB) asia-northeast1 a3-highgpu-8g"
              value: "H100(80GB) asia-northeast1 a3-highgpu-8g"
            - label: "H100(80GB) asia-southeast1 a3-highgpu-8g"
              value: "H100(80GB) asia-southeast1 a3-highgpu-8g"
            - label: "H100(80GB) europe-west1 a3-highgpu-8g"
              value: "H100(80GB) europe-west1 a3-highgpu-8g"
            - label: "H100(80GB) us-central1 a3-highgpu-8g"
              value: "H100(80GB) us-central1 a3-highgpu-8g"
            - label: "H100(80GB) us-east4 a3-highgpu-8g"
              value: "H100(80GB) us-east4 a3-highgpu-8g"
            - label: "H100(80GB) us-west1 a3-highgpu-8g"
              value: "H100(80GB) us-west1 a3-highgpu-8g"
            - label: "H100(80GB) us-west4 a3-highgpu-8g"
              value: "H100(80GB) us-west4 a3-highgpu-8g"
            - label: "A100(80GB) asia-southeast1 a2-ultragpu-1g"
              value: "A100(80GB) asia-southeast1 a2-ultragpu-1g"
            - label: "A100(80GB) europe-west4 a2-ultragpu-1g"
              value: "A100(80GB) europe-west4 a2-ultragpu-1g"
            - label: "A100(80GB) us-central1 a2-ultragpu-1g"
              value: "A100(80GB) us-central1 a2-ultragpu-1g"
            - label: "A100(80GB) us-east4 a2-ultragpu-1g"
              value: "A100(80GB) us-east4 a2-ultragpu-1g"
            - label: "A100(80GB) asia-southeast1 a2-ultragpu-4g"
              value: "A100(80GB) asia-southeast1 a2-ultragpu-4g"
            - label: "A100(80GB) europe-west4 a2-ultragpu-4g"
              value: "A100(80GB) europe-west4 a2-ultragpu-4g"
            - label: "A100(80GB) us-central1 a2-ultragpu-4g"
              value: "A100(80GB) us-central1 a2-ultragpu-4g"
            - label: "A100(80GB) us-east4 a2-ultragpu-4g"
              value: "A100(80GB) us-east4 a2-ultragpu-4g"
            - label: "A100(80GB) asia-northeast1 a2-ultragpu-8g"
              value: "A100(80GB) asia-northeast1 a2-ultragpu-8g"
            - label: "A100(80GB) asia-south1 a2-ultragpu-8g"
              value: "A100(80GB) asia-south1 a2-ultragpu-8g"
            - label: "A100(80GB) europe-west1 a2-ultragpu-8g"
              value: "A100(80GB) europe-west1 a2-ultragpu-8g"
            - label: "A100(80GB) us-central1 a2-ultragpu-8g"
              value: "A100(80GB) us-central1 a2-ultragpu-8g"
            - label: "A100(80GB) us-east4 a2-ultragpu-8g"
              value: "A100(80GB) us-east4 a2-ultragpu-8g"
            - label: "A100(80GB) us-west1 a2-ultragpu-8g"
              value: "A100(80GB) us-west1 a2-ultragpu-8g"
        model_name:
          name: model_name
          title: NIM Model name
          section: required_config
          enumValueLabels:
            - label: meta/llama-3.1-8b-instruct
              value: llama-3.1-8b-instruct
            - label: meta/llama-3.1-70b-instruct
              value: llama-3.1-70b-instruct   
            - label: meta/llama-3.1-405b-instruct
              value: llama-3.1-405b-instruct
            - label: meta/llama3-8b-instruct
              value: llama3-8b-instruct
            - label: meta/llama3-70b-instruct
              value: llama3-70b-instruct
            - label: mistralai/mixtral-8x7b-instruct-v0.1
              value: mixtral-8x7b-instruct-v01
            - label: mistralai/mistral-7b-instruct-v0.3
              value: mistral-7b-instruct-v0.3
            - label: nvidia/nv-rerankqa-mistral-4b-v3
              value: nv-rerankqa-mistral-4b-v3
            - label: nvidia/nv-embedqa-e5-v5
              value: nv-embedqa-e5-v5
            - label: nvidia/nv-embedqa-mistral-7b-v2
              value: nv-embedqa-mistral-7b-v2
        nim_license:
          name: nim_license
          title: I agree to the Terms and Conditions
          section: license
        gpu_limits:
          name: gpu_limits
          title: GPU limits
          section: required_config
          invisible: true 
      sections:
        - name: acknowledge
          title: Before you begin
          subtext:
                This solution deploys a <a href="https://github.com/NVIDIA/nim-deploy/tree/main/cloud-service-providers/google-cloud/gke/README.md#nvidia-nims-on-gke"><i>NVIDIA NIM</i></a> application on GKE in your project.</br>
        - name: required_config
          title: Required configuration
        - name: license
          title: Governing Terms & Conditions
          subtext: 
                <p>
                The NIM container is governed by <a href="https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-software-license-agreement/">NVIDIA Agreements | Enterprise Software | NVIDIA Software License Agreement</a> and <a href="https://www.nvidia.com/en-us/agreements/enterprise-software/product-specific-terms-for-ai-products/">NVIDIA Agreements | Enterprise Software | Product Specific Terms for AI Product</a>; and the use of the model is governed by governed by the <a href="https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-ai-foundation-models-community-license-agreement/">NVIDIA AI Foundation Models Community License Agreement.</a><br/>
                <b>Additional Information</b><br/>
                &emsp;&emsp;&#x2022; For Llama-3.1 models&#58; <a href="https://www.llama.com/llama3_1/license/">Llama 3.1 Community License Agreement, Built with Llama</a><br/>
                &emsp;&emsp;&#x2022; For Llama3 models&#58; <a href="https://www.llama.com/llama3/license/">Meta Llama 3 Community License, Built with Meta Llama 3</a><br/>
                &emsp;&emsp;&#x2022; For Mistral models&#58; <a href="https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2">Apache 2.0 License</a><br/>
                &emsp;&emsp;&#x2022; For Mixtral models&#58; <a href="https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2">Apache 2.0 License</a><br/>
                &emsp;&emsp;&#x2022; For E5-Large models&#58; <a href="https://choosealicense.com/licenses/mit/">MIT license</a><br/>
                </p>
    runtime:
      outputMessage: Deployment can take several minutes to complete.
      suggestedActions:
        - heading: Connect to GKE Cluster
          description: Connect to GKE Cluster. Open another terminal and follow these <a href="https://github.com/NVIDIA/nim-deploy/tree/main/cloud-service-providers/google-cloud/gke/README.md#inference">instructions</a> to run inference.
      outputs:
        cluster_name: {}
        cluster_location: {}
        project_id: {}
        endpoint: {}
