# AIRA overrides for EKS. Keep this minimal and environment-specific.
# Secrets (NGC, Tavily, etc.) should be passed via --set or managed as K8s Secrets.
#
# This file uses environment variable substitution. Before deploying, run:
#   export SECONDARY_GPU_NODE=$(kubectl get nodes -l role=gpu-secondary -o jsonpath='{.items[0].metadata.name}')
#   envsubst '$SECONDARY_GPU_NODE' < aira-values.eks.yaml.template > aira-values.eks.yaml

# AIRA deployment namespace
namespace: "nv-aira"

# AIRA backend service
service:
  type: ClusterIP
  port: 3838
  targetPort: 3838

frontend:
  enabled: true
  proxyUrl: http://aira-nginx.nv-aira.svc.cluster.local:8051
  service:
    type: LoadBalancer
    port: 3001
    targetPort: 3001

# Enables the Phoenix tracing service
phoenix:
  enabled: true
  image:
    repository: arizephoenix/phoenix
    tag: latest
    pullPolicy: IfNotPresent
  resources:
    limits:
      cpu: 500m
      memory: 512Mi
    requests:
      cpu: 200m
      memory: 256Mi

nim-llm:
  enabled: true  # Deploy model for AIRA report generation
  image:
    repository: nvcr.io/nim/meta/llama-3.1-8b-instruct # # Change to nvcr.io/nim/meta/llama-3.3-70b-instruct for a larger model
    tag: "1.8.4"
  resources:
    limits:
      nvidia.com/gpu: 1
    requests:
      nvidia.com/gpu: 1
  model:
    name: "meta/llama-3.1-8b-instruct" # # Change to meta/llama-3.3-70b-instruct for a larger model
  # Pin to Secondary Node 
  nodeSelector:
    kubernetes.io/hostname: $SECONDARY_GPU_NODE

config:
  instruct_model_name: "meta/llama-3.1-8b-instruct" # Change to # Change to meta/llama-3.3-70b-instruct for a larger model
  instruct_base_url: "http://nim-llm.nv-aira.svc.cluster.local:8000/v1"  
  nemotron_model_name: "nvidia/llama-3.3-nemotron-super-49b-v1.5"
  nemotron_base_url: "http://nim-llm.nv-nvidia-blueprint-rag.svc.cluster.local:8000/v1"
  # RAG server integration for chat functionality  
  rag_url: "http://rag-server.nv-nvidia-blueprint-rag.svc.cluster.local:8081"
  rag_ingest_url: "http://ingestor-server.nv-nvidia-blueprint-rag.svc.cluster.local:8082"
  milvus_host: "milvus.nv-nvidia-blueprint-rag.svc.cluster.local"
  milvus_port: "19530"

# Override nginx configuration for EKS-specific namespaces
nginx:
  nginx_config:
    conf: |-
      worker_processes auto;

      events {
          worker_connections 1024;
      }

      http {
          proxy_ssl_server_name on;

          proxy_cache_path /server_cache_llm levels=1:2 keys_zone=llm_cache:10m max_size=20g inactive=14d use_temp_path=off;

          proxy_cache_path /server_cache_intel levels=1:2 keys_zone=intel_cache:10m max_size=20g inactive=14d use_temp_path=off;

          error_log /dev/stdout info;

          log_format upstream_time '$remote_addr - $remote_user [$time_local] '
                                  '"$request" $status $body_bytes_sent '
                                  '"$http_referer" "$http_user_agent"'
                                  'rt=$request_time uct="$upstream_connect_time" uht="$upstream_header_time" urt="$upstream_response_time"';

          log_format cache_log '[$time_local] ($upstream_cache_status) "$request" $status - $body_bytes_sent bytes {$remote_addr} "$http_user_agent" $request_time - $connection_requests. Auth: $http_authorization';

          log_format no_cache_log '[$time_local] (BYPASSED) "$request" $status - $body_bytes_sent bytes {$remote_addr} "$http_user_agent" $request_time - $connection_requests. Auth: $http_authorization';

          log_format mirror_log '[$time_local] (MIRROR) "$request" $status - $body_bytes_sent bytes {$remote_addr} "$http_user_agent" $request_time - $connection_requests. Auth: $http_authorization';

          log_format nvai_cache_log '[$time_local] ($upstream_cache_status) "$request" $status - $body_bytes_sent bytes {$remote_addr} "$http_user_agent" $request_time - $connection_requests. Auth: $http_authorization. $upstream_addr';

          map $http_cache_control $cache_bypass {
              no-cache   1;
          }

          # Log to stdout and a file for searchability
          access_log /dev/stdout cache_log;
          access_log /var/log/nginx/access.log cache_log;

          error_log /dev/stdout info;
          error_log /var/log/nginx/error.log info;

          server {
            listen 8051;
            server_name _;

            # Common proxy settings
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_pass_request_headers on;

            # Common buffer settings
            large_client_header_buffers 4 32k;
            client_header_buffer_size 4k;

            # Common timeout settings
            client_body_timeout 900s;
            client_header_timeout 900s;

            # Common settings for document-related endpoints
            proxy_read_timeout 600s;
            proxy_connect_timeout 60s;
            proxy_send_timeout 600s;
            client_max_body_size 100M;
            proxy_max_temp_file_size 0;
            proxy_buffering on;
            proxy_buffer_size 1M;
            proxy_buffers 100 1M;
            proxy_busy_buffers_size 2M;

            # RAG routes (override with EKS-specific namespace)
            location ~ ^/v1/(status|documents|collections) {
                proxy_pass http://ingestor-server.nv-nvidia-blueprint-rag.svc.cluster.local:8082/$1$is_args$args;
                proxy_set_header Host $host;
            }

            # Protected RAG routes
            location ~ ^/v2/protected/aiq/v1/(status|documents|collections) {
                proxy_pass http://ingestor-server.nv-nvidia-blueprint-rag.svc.cluster.local:8082/$1$is_args$args;
                proxy_set_header Host $host;
            }

            # Special case for files route
            location /v2/protected/aiq/v1/files {
                proxy_pass http://ingestor-server.nv-nvidia-blueprint-rag.svc.cluster.local:8082/v1/documents;
                proxy_set_header Host $host;
            }

            # AIRA routes with path rewriting (override with EKS-specific namespace)
            location ~ ^/v2/protected/aiq/v1/(generate_query|generate_summary|artifact_qa|default_collections)(.*)$ {
                rewrite ^/v2/protected/aiq/v1/(.*)$ /$1 break;
                proxy_pass http://aira-aira-backend.nv-aira.svc.cluster.local:3838;
                proxy_set_header Host $host;
            }

            # Health routes
            location /v2/protected/aiq/keepalive {
                default_type text/plain;
                return 200 "OK";
            }

            location /v2/protected/aiq/health {
                default_type text/plain;
                return 200 "OK";
            }
            
            location = /health {
                default_type text/plain;
                return 200 "OK";
            }

            location = /keepalive {
                default_type text/plain;
                return 200 "OK";
            }

            # Catch-all for other protected routes
            location /v2/protected/aiq/ {
                rewrite ^/v2/protected/aiq/(.*) /$1 break;
                proxy_pass http://aira-aira-backend.nv-aira.svc.cluster.local:3838;
                proxy_set_header Host $host;
            }

            # Default location for all other routes
            location / {
                proxy_pass http://aira-aira-backend.nv-aira.svc.cluster.local:3838;
                proxy_set_header Host $host;
            }

            error_page 500 502 503 504 /50x.html;
            location = /50x.html {
                root /usr/share/nginx/html;
            }
        }
      }


