{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NVIDIA NIM TTS Model Deployment on Amazon SageMaker AI\n",
        "\n",
        "## Introduction\n",
        "\n",
        "This notebook demonstrates how to deploy the **NVIDIA NIM TTS (Magpie TTS Multilingual)** model for Text-to-Speech (TTS) tasks using Amazon SageMaker with a custom container that supports both HTTP and gRPC protocols.\n",
        "\n",
        "### About NVIDIA NIM TTS (Magpie)\n",
        "\n",
        "The **NVIDIA NIM TTS Magpie Multilingual** provides a production-ready text-to-speech service:\n",
        "\n",
        "- **Architecture**: HTTP + gRPC routing to NVIDIA NIM TTS container\n",
        "- **Model**: Magpie TTS Multilingual optimized for high-quality speech synthesis\n",
        "- **Performance**: Low latency, high-quality audio output\n",
        "- **Features**: Multiple voices, languages, zero-shot voice cloning, custom dictionaries\n",
        "- **Deployment**: Ready for SageMaker real-time inference\n",
        "\n",
        "### Key Features\n",
        "\n",
        "1. **Dual Protocol Support**: HTTP for simple requests, gRPC for advanced features\n",
        "2. **Multilingual Support**: Multiple languages and voices available\n",
        "3. **Zero-Shot Voice Cloning**: Clone voices from audio prompts (gRPC)\n",
        "4. **Custom Dictionaries**: Define custom pronunciations (gRPC)\n",
        "5. **End-to-End Streaming**: True streaming via `InvokeEndpointWithResponseStream` API\n",
        "6. **Production Ready**: Built with NVIDIA NIM for enterprise deployment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites and Setup\n",
        "\n",
        "**â— Important Notes:**\n",
        "- Docker is required to pull and push container images\n",
        "- You need an **NGC_API_KEY** from NVIDIA NGC ([Get one here](https://build.nvidia.com))\n",
        "- ECR permissions are required for pushing Docker images to your private ECR\n",
        "- NIM ECR image is currently available only in `us-east-1` region\n",
        "\n",
        "**Supported AWS Instances (Compute Capability >= 8.0):**\n",
        "\n",
        "| Instance Family | GPU | Examples |\n",
        "|-----------------|-----|----------|\n",
        "| ml.g6e.* | L40S | ml.g6e.xlarge, ml.g6e.2xlarge |\n",
        "| ml.p4d.* | A100 | ml.p4d.24xlarge |\n",
        "| ml.p5.* | H100 | ml.p5.48xlarge |\n",
        "\n",
        "> âš ï¸ Other GPU instances (g4dn, g5, p3) are **not supported**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install sagemaker>=2.246.0 boto3 soundfile --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required packages\n",
        "import boto3\n",
        "import json\n",
        "import sagemaker\n",
        "import time\n",
        "import os\n",
        "from sagemaker import get_execution_role\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup AWS clients and session\n",
        "sess = boto3.Session()\n",
        "sm = sess.client(\"sagemaker\")\n",
        "sagemaker_session = sagemaker.Session(boto_session=sess)\n",
        "role = get_execution_role()\n",
        "sm_runtime = boto3.client(\"sagemaker-runtime\")\n",
        "region = sess.region_name\n",
        "sts_client = sess.client('sts')\n",
        "account_id = sts_client.get_caller_identity()['Account']\n",
        "\n",
        "print(f\"Region: {region}\")\n",
        "print(f\"Account ID: {account_id}\")\n",
        "print(f\"Role: {role}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define deployment arguments\n",
        "public_nim_image = \"public.ecr.aws/nvidia/nim:magpie-tts-multilingual-1.6.0\"\n",
        "nim_model = \"magpie-tts-multilingual\"\n",
        "sm_model_name = \"nim-tts-magpie-multilingual\"\n",
        "instance_type = \"ml.g6e.xlarge\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NIM Container Setup\n",
        "\n",
        "Pull the NIM image from public ECR and push to your private ECR repository:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pull NIM image from public ECR and push to private ECR\n",
        "\n",
        "import subprocess\n",
        "\n",
        "print(f\"Public NIM Image: {public_nim_image}\")\n",
        "print(f\"Target model name: {nim_model}\")\n",
        "\n",
        "bash_script = f\"\"\"\n",
        "echo \"Public NIM Image: {public_nim_image}\"\n",
        "docker pull {public_nim_image}\n",
        "\n",
        "echo \"Resolved account: {account_id}\"\n",
        "echo \"Resolved region: {region}\"\n",
        "\n",
        "nim_image=\"{account_id}.dkr.ecr.{region}.amazonaws.com/{nim_model}\"\n",
        "\n",
        "# Ensure the repository name adheres to AWS constraints\n",
        "repository_name=$(echo \"{nim_model}\" | tr '[:upper:]' '[:lower:]' | tr -cd '[:alnum:]._/-')\n",
        "\n",
        "# If the repository doesn't exist in ECR, create it.\n",
        "aws ecr describe-repositories --repository-names \"$repository_name\" > /dev/null 2>&1\n",
        "\n",
        "if [ $? -ne 0 ]\n",
        "then\n",
        "    aws ecr create-repository --repository-name \"$repository_name\" > /dev/null\n",
        "    echo \"âœ… Created ECR repository: $repository_name\"\n",
        "else\n",
        "    echo \"âœ… ECR repository already exists: $repository_name\"\n",
        "fi\n",
        "\n",
        "# Get the login command from ECR and execute it directly\n",
        "aws ecr get-login-password --region {region} | docker login --username AWS --password-stdin \"{account_id}.dkr.ecr.{region}.amazonaws.com\"\n",
        "\n",
        "docker tag {public_nim_image} $nim_image\n",
        "docker push $nim_image\n",
        "echo \"âœ… Image pushed successfully\"\n",
        "echo -n $nim_image\n",
        "\"\"\"\n",
        "\n",
        "nim_image = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{nim_model}\"\n",
        "\n",
        "# Run the bash script and capture real-time output\n",
        "process = subprocess.Popen(bash_script, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "while True:\n",
        "    output = process.stdout.readline()\n",
        "    if output == b'' and process.poll() is not None:\n",
        "        break\n",
        "    if output:\n",
        "        print(output.decode().strip())\n",
        "\n",
        "stderr = process.stderr.read().decode()\n",
        "if stderr:\n",
        "    print(\"Errors:\", stderr)\n",
        "\n",
        "print(f\"\\nðŸŽ¯ Private ECR Image: {nim_image}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print the private ECR NIM image that will be used for SageMaker deployment\n",
        "print(f\"NIM Image URI: {nim_image}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create SageMaker Endpoint\n",
        "\n",
        "**Before proceeding further, please set your NGC API Key.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SET YOUR NGC API KEY HERE\n",
        "# Required for running NIM - get yours from https://build.nvidia.com\n",
        "NGC_API_KEY = None  # <-- SET ME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate NGC API Key\n",
        "assert NGC_API_KEY is not None, \"NGC API KEY is not set. Please set the NGC_API_KEY variable in the previous cell.\"\n",
        "print(\"âœ… NGC_API_KEY is set\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create SageMaker model with NIM container\n",
        "container = {\n",
        "    \"Image\": nim_image,\n",
        "    \"Environment\": {\n",
        "        \"NGC_API_KEY\": NGC_API_KEY,\n",
        "        \"CUDA_VISIBLE_DEVICES\": \"0\"\n",
        "    }\n",
        "}\n",
        "\n",
        "create_model_response = sm.create_model(\n",
        "    ModelName=sm_model_name, \n",
        "    ExecutionRoleArn=role, \n",
        "    PrimaryContainer=container\n",
        ")\n",
        "\n",
        "print(\"Model Arn: \" + create_model_response[\"ModelArn\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create endpoint configuration\n",
        "endpoint_config_name = sm_model_name\n",
        "\n",
        "create_endpoint_config_response = sm.create_endpoint_config(\n",
        "    EndpointConfigName=endpoint_config_name,\n",
        "    ProductionVariants=[\n",
        "        {\n",
        "            \"InstanceType\": instance_type,\n",
        "            \"InitialVariantWeight\": 1,\n",
        "            \"InitialInstanceCount\": 1,\n",
        "            \"ModelName\": sm_model_name,\n",
        "            \"VariantName\": \"AllTraffic\",\n",
        "            \"ContainerStartupHealthCheckTimeoutInSeconds\": 1800,\n",
        "            \"InferenceAmiVersion\": \"al2-ami-sagemaker-inference-gpu-2\"\n",
        "        }\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(\"Endpoint Config Arn: \" + create_endpoint_config_response[\"EndpointConfigArn\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create endpoint\n",
        "endpoint_name = sm_model_name\n",
        "\n",
        "create_endpoint_response = sm.create_endpoint(\n",
        "    EndpointName=endpoint_name, \n",
        "    EndpointConfigName=endpoint_config_name\n",
        ")\n",
        "\n",
        "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Wait for endpoint to be in service\n",
        "resp = sm.describe_endpoint(EndpointName=endpoint_name)\n",
        "status = resp[\"EndpointStatus\"]\n",
        "print(\"Status: \" + status)\n",
        "\n",
        "while status == \"Creating\":\n",
        "    time.sleep(60)\n",
        "    resp = sm.describe_endpoint(EndpointName=endpoint_name)\n",
        "    status = resp[\"EndpointStatus\"]\n",
        "    print(\"Status: \" + status)\n",
        "\n",
        "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
        "print(\"Status: \" + status)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inference Testing\n",
        "\n",
        "### API Request Format\n",
        "\n",
        "The request body follows the [NVIDIA Riva TTS SynthesizeSpeechRequest proto](https://docs.nvidia.com/nim/riva/tts/1.6.0/protos.html#nvidia-riva-tts-synthesizespeechrequest):\n",
        "\n",
        "| Field | Type | Required | Description |\n",
        "|-------|------|----------|-------------|\n",
        "| `text` | string | âœ… Yes | Text to synthesize |\n",
        "| `voice_name` | string | No | Voice name ([available voices](https://docs.nvidia.com/nim/riva/tts/1.10.0/support-matrix.html#available-voices)) |\n",
        "| `language_code` | string | No | Language code: en-US, es-US, fr-FR, de-DE, zh-CN, vi-VN, it-IT ([docs](https://docs.nvidia.com/nim/riva/tts/1.10.0/support-matrix.html#magpie-tts-multilingual)) |\n",
        "| `sample_rate_hz` | int | No | Sample rate (default: 44100) |\n",
        "| `encoding` | string | No | `LINEAR_PCM` or `OGGOPUS` |\n",
        "| `zero_shot_data` | object | No | `{audio_prompt, quality, transcript}` for voice cloning (gRPC only) |\n",
        "| `custom_dictionary` | string | No | `\"word1  pron1,word2  pron2\"` with double-space separator (gRPC only) |\n",
        "\n",
        "### Response Format\n",
        "\n",
        "Response matches [NIM SynthesizeSpeechResponse](https://docs.nvidia.com/nim/riva/tts/1.6.0/protos.html#nvidia-riva-tts-synthesizespeechresponse):\n",
        "\n",
        "| Field | Type | Description |\n",
        "|-------|------|-------------|\n",
        "| `audio` | string | Base64-encoded audio bytes |\n",
        "| `meta` | object | Optional metadata from NIM |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### Non-Streaming Request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import base64\n",
        "import IPython.display as ipd\n",
        "\n",
        "payload = {\n",
        "    \"text\": \"Hello! This is a test of NVIDIA TTS on Amazon SageMaker.\",\n",
        "    \"language_code\": \"en-US\",\n",
        "    \"sample_rate_hz\": 44100,\n",
        "    \"encoding\": \"LINEAR_PCM\"\n",
        "}\n",
        "\n",
        "response = sm_runtime.invoke_endpoint(\n",
        "    EndpointName=endpoint_name,\n",
        "    ContentType=\"application/json\",\n",
        "    Body=json.dumps(payload)\n",
        ")\n",
        "\n",
        "result = json.loads(response[\"Body\"].read().decode(\"utf8\"))\n",
        "print(json.dumps({k: v[:50] + \"...\" if k == \"audio\" else v for k, v in result.items()}, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract audio from response and play\n",
        "audio_bytes = base64.b64decode(result[\"audio\"])\n",
        "print(f\"Audio size: {len(audio_bytes):,} bytes\")\n",
        "\n",
        "with open(\"tts_output.wav\", \"wb\") as f:\n",
        "    f.write(audio_bytes)\n",
        "\n",
        "ipd.Audio(\"tts_output.wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Transport Selection (Optional)\n",
        "\n",
        "Use `CustomAttributes` header to select HTTP or gRPC transport:\n",
        "\n",
        "| CustomAttributes | Description |\n",
        "|------------------|-------------|\n",
        "| `/invocations/http` | Force HTTP transport |\n",
        "| `/invocations/grpc` | Force gRPC transport |\n",
        "| *(not set)* | Auto-routing |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "payload = {\n",
        "    \"text\": \"This audio is generated using gRPC transport.\",\n",
        "    \"language_code\": \"en-US\",\n",
        "    \"sample_rate_hz\": 44100\n",
        "}\n",
        "\n",
        "response = sm_runtime.invoke_endpoint(\n",
        "    EndpointName=endpoint_name,\n",
        "    ContentType=\"application/json\",\n",
        "    CustomAttributes=\"/invocations/grpc\",\n",
        "    Body=json.dumps(payload)\n",
        ")\n",
        "\n",
        "result = json.loads(response[\"Body\"].read().decode(\"utf8\"))\n",
        "audio_bytes = base64.b64decode(result[\"audio\"])\n",
        "print(f\"Audio size: {len(audio_bytes):,} bytes\")\n",
        "\n",
        "with open(\"tts_grpc.wav\", \"wb\") as f:\n",
        "    f.write(audio_bytes)\n",
        "\n",
        "ipd.Audio(\"tts_grpc.wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using a Specific Voice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "payload = {\n",
        "    \"text\": \"This audio uses a specific voice.\",\n",
        "    \"voice_name\": \"Magpie-Multilingual.EN-US.Aria\",\n",
        "    \"language_code\": \"en-US\",\n",
        "    \"sample_rate_hz\": 44100\n",
        "}\n",
        "\n",
        "response = sm_runtime.invoke_endpoint(\n",
        "    EndpointName=endpoint_name,\n",
        "    ContentType=\"application/json\",\n",
        "    Body=json.dumps(payload)\n",
        ")\n",
        "\n",
        "result = json.loads(response[\"Body\"].read().decode(\"utf8\"))\n",
        "audio_bytes = base64.b64decode(result[\"audio\"])\n",
        "print(f\"Audio size: {len(audio_bytes):,} bytes\")\n",
        "\n",
        "with open(\"tts_voice.wav\", \"wb\") as f:\n",
        "    f.write(audio_bytes)\n",
        "\n",
        "ipd.Audio(\"tts_voice.wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom Dictionary (gRPC-only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "payload = {\n",
        "    \"text\": \"Welcome to NVIDIA and Amazon SageMaker integration.\",\n",
        "    \"language_code\": \"en-US\",\n",
        "    \"sample_rate_hz\": 44100,\n",
        "    \"custom_dictionary\": \"NVIDIA  en-vid-ee-ah,SageMaker  sage-may-ker\"\n",
        "}\n",
        "\n",
        "response = sm_runtime.invoke_endpoint(\n",
        "    EndpointName=endpoint_name,\n",
        "    ContentType=\"application/json\",\n",
        "    Body=json.dumps(payload)\n",
        ")\n",
        "\n",
        "result = json.loads(response[\"Body\"].read().decode(\"utf8\"))\n",
        "audio_bytes = base64.b64decode(result[\"audio\"])\n",
        "print(f\"Audio size: {len(audio_bytes):,} bytes\")\n",
        "\n",
        "with open(\"tts_custom_dict.wav\", \"wb\") as f:\n",
        "    f.write(audio_bytes)\n",
        "\n",
        "ipd.Audio(\"tts_custom_dict.wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### Streaming Request\n",
        "\n",
        "For streaming, use `invoke_endpoint_with_response_stream` with `CustomAttributes=\"/invocations/stream\"`.\n",
        "\n",
        "The payload is the same - streaming is enabled by the API and header, not the payload."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "payload = {\n",
        "    \"text\": \"Welcome to streaming text-to-speech on Amazon SageMaker. \"\n",
        "            \"This demonstrates how audio chunks are delivered incrementally.\",\n",
        "    \"language_code\": \"en-US\",\n",
        "    \"sample_rate_hz\": 44100,\n",
        "    \"encoding\": \"LINEAR_PCM\"\n",
        "}\n",
        "\n",
        "response = sm_runtime.invoke_endpoint_with_response_stream(\n",
        "    EndpointName=endpoint_name,\n",
        "    ContentType=\"application/json\",\n",
        "    CustomAttributes=\"/invocations/stream\",\n",
        "    Body=json.dumps(payload)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process streaming response - collect chunks\n",
        "import wave\n",
        "import io\n",
        "\n",
        "chunks = []\n",
        "for event in response[\"Body\"]:\n",
        "    if \"PayloadPart\" in event:\n",
        "        chunk = event[\"PayloadPart\"][\"Bytes\"]\n",
        "        if chunk:\n",
        "            chunks.append(chunk)\n",
        "            print(f\"Received chunk: {len(chunk):,} bytes\")\n",
        "\n",
        "raw_pcm = b\"\".join(chunks)\n",
        "print(f\"\\nTotal PCM bytes: {len(raw_pcm):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert PCM to WAV and play\n",
        "def pcm_to_wav(pcm_data, sample_rate=44100, channels=1, bits_per_sample=16):\n",
        "    buffer = io.BytesIO()\n",
        "    with wave.open(buffer, \"wb\") as wav_file:\n",
        "        wav_file.setnchannels(channels)\n",
        "        wav_file.setsampwidth(bits_per_sample // 8)\n",
        "        wav_file.setframerate(sample_rate)\n",
        "        wav_file.writeframesraw(pcm_data)\n",
        "    return buffer.getvalue()\n",
        "\n",
        "wav_data = pcm_to_wav(raw_pcm, sample_rate=44100)\n",
        "with open(\"tts_streaming.wav\", \"wb\") as f:\n",
        "    f.write(wav_data)\n",
        "\n",
        "print(f\"WAV file size: {len(wav_data):,} bytes\")\n",
        "ipd.Audio(\"tts_streaming.wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Live Streaming Demo\n",
        "\n",
        "Watch chunks arrive in real-time:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "payload = {\n",
        "    \"text\": \"This is a live streaming demonstration. Watch as each audio chunk arrives \"\n",
        "            \"from the NVIDIA NIM TTS model in real-time.\",\n",
        "    \"language_code\": \"en-US\",\n",
        "    \"sample_rate_hz\": 44100,\n",
        "    \"encoding\": \"LINEAR_PCM\"\n",
        "}\n",
        "\n",
        "response = sm_runtime.invoke_endpoint_with_response_stream(\n",
        "    EndpointName=endpoint_name,\n",
        "    ContentType=\"application/json\",\n",
        "    CustomAttributes=\"/invocations/stream\",\n",
        "    Body=json.dumps(payload)\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "chunk_count = 0\n",
        "total_bytes = 0\n",
        "\n",
        "for event in response[\"Body\"]:\n",
        "    if \"PayloadPart\" in event:\n",
        "        chunk = event[\"PayloadPart\"][\"Bytes\"]\n",
        "        if chunk:\n",
        "            chunk_count += 1\n",
        "            total_bytes += len(chunk)\n",
        "            elapsed = time.time() - start_time\n",
        "            print(f\"ðŸ“¦ Chunk {chunk_count:3d} | {len(chunk):6,} bytes | Total: {total_bytes:8,} | @{elapsed:.2f}s\")\n",
        "            sys.stdout.flush()\n",
        "\n",
        "print(f\"\\nâœ… Stream complete: {chunk_count} chunks, {total_bytes:,} bytes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Resource Cleanup\n",
        "\n",
        "**âš ï¸ Cost Warning**: Delete resources when done testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sm.delete_model(ModelName=sm_model_name)\n",
        "print(f\"âœ… Model {sm_model_name} deleted\")\n",
        "\n",
        "sm.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
        "print(f\"âœ… Endpoint config {endpoint_config_name} deleted\")\n",
        "\n",
        "sm.delete_endpoint(EndpointName=endpoint_name)\n",
        "print(f\"âœ… Endpoint {endpoint_name} deleted\")\n",
        "\n",
        "# Clean up audio files\n",
        "import glob\n",
        "for f in glob.glob(\"tts_*.wav\"):\n",
        "    os.remove(f)\n",
        "    print(f\"âœ… Removed {f}\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
