{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0488cae-f2b2-4d0f-9e42-7cd4faae07d8",
   "metadata": {},
   "source": [
    "# Deploy NVIDIA NIM from AWS Marketplace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cf191c-ac98-4d56-a6e5-a43e6de87b13",
   "metadata": {},
   "source": [
    "NVIDIA NIM, a component of NVIDIA AI Enterprise, enhances your applications with the power of state-of-the-art large language models (LLMs), providing unmatched natural language processing and understanding capabilities. Whether you're developing chatbots, content analyzers, or any application that needs to understand and generate human language, NVIDIA NIM for LLMs has you covered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1048b66-14f3-4f47-91fd-e653979c7cd5",
   "metadata": {},
   "source": [
    "In this example we show how to deploy the Cosmos-Reason1-7B model from AWS Marketplace\n",
    "\n",
    "NVIDIA Cosmos Reason – an open, customizable, 7B-parameter reasoning vision language model (VLM) for physical AI and robotics - enables robots and vision AI agents to reason like humans, using prior knowledge, physics understanding and common sense to understand and act in the real world. This model understands space, time, and fundamental physics, and can serve as a planning model to reason what steps an embodied agent might take next.\n",
    "\n",
    "Given a video and a text prompt, the model first converts the video into tokens using a vision encoder and a special translator called a projector. These video tokens are combined with the text prompt and fed into the core model, which uses a mix of LLM modules and techniques. This enables the model to think step-by-step and provide detailed, logical responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee1f3df-a66e-490e-b4dc-7aa7b3a0ed6e",
   "metadata": {},
   "source": [
    "Please check out the [Cosmos-Reason1-7B model card](https://build.nvidia.com/nvidia/cosmos-reason1-7b/modelcard) and [NIM LLM docs](https://docs.nvidia.com/nim/large-language-models/latest/introduction.html) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49c8cfe",
   "metadata": {},
   "source": [
    "## ⚠️ Disclaimer\n",
    "\n",
    "Reasoning models often require longer inference times, which may exceed the default 60-second timeout limit for [**AWS SageMaker's non-streaming endpoints**](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_runtime_InvokeEndpoint.html). This notebook shows examples for both the streaming and non-streaming endpoints.\n",
    "\n",
    "To avoid inference failures due to timeout:\n",
    "- It is **recommended** to use the **SageMaker streaming endpoint** for this model as shown in the [Streaming inference](#Streaming-inference) section of this notebook.\n",
    "- If your use case **requires** using a **non-streaming endpoint** as shown in the [Run Inference](#Run-Inference) section of this notebook, you must first contact **AWS Support** to request an increased timeout limit for your **AWS Account and Region** to avoid unexpected errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740a3631-f207-4803-98ed-45d6895aa80a",
   "metadata": {},
   "source": [
    "## Pre-requisites:\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. To deploy this ML model successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to one of the models listed above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5004eb9a-5817-484c-a412-2ce80a2e2f36",
   "metadata": {},
   "source": [
    "## Subscribe to the model package\n",
    "To subscribe to the model package:\n",
    "1. Open the model package listing page\n",
    "1. On the AWS Marketplace listing, click on the **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you and your organization agrees with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn** displayed. This is the model package ARN that you need to specify while creating a deployable model. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288fcdc9-3dbd-4bff-8e49-40783a5a2b3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3, json, sagemaker, time, os\n",
    "from sagemaker import get_execution_role, ModelPackage\n",
    "from botocore.config import Config\n",
    "\n",
    "config = Config(read_timeout=3600)\n",
    "sess = boto3.Session()\n",
    "sm = sess.client(\"sagemaker\")\n",
    "sagemaker_session = sagemaker.Session(boto_session=sess)\n",
    "role = get_execution_role()\n",
    "client = boto3.client(\"sagemaker-runtime\", config=config)\n",
    "region = sess.region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc82963-2d0b-4fb6-8ef4-a0e5f6a15c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the arn below with the model package arn you want to deploy\n",
    "nim_package = \"\"\n",
    "\n",
    "# Mapping for Model Packages\n",
    "model_package_map = {\n",
    "    \"us-east-1\": f\"arn:aws:sagemaker:us-east-1:865070037744:model-package/{nim_package}\",\n",
    "    \"us-east-2\": f\"arn:aws:sagemaker:us-east-2:057799348421:model-package/{nim_package}\",\n",
    "    \"us-west-1\": f\"arn:aws:sagemaker:us-west-1:382657785993:model-package/{nim_package}\",\n",
    "    \"us-west-2\": f\"arn:aws:sagemaker:us-west-2:594846645681:model-package/{nim_package}\",\n",
    "    \"ca-central-1\": f\"arn:aws:sagemaker:ca-central-1:470592106596:model-package/{nim_package}\",\n",
    "    \"eu-central-1\": f\"arn:aws:sagemaker:eu-central-1:446921602837:model-package/{nim_package}\",\n",
    "    \"eu-west-1\": f\"arn:aws:sagemaker:eu-west-1:985815980388:model-package/{nim_package}\",\n",
    "    \"eu-west-2\": f\"arn:aws:sagemaker:eu-west-2:856760150666:model-package/{nim_package}\",\n",
    "    \"eu-west-3\": f\"arn:aws:sagemaker:eu-west-3:843114510376:model-package/{nim_package}\",\n",
    "    \"eu-north-1\": f\"arn:aws:sagemaker:eu-north-1:136758871317:model-package/{nim_package}\",\n",
    "    \"ap-southeast-1\": f\"arn:aws:sagemaker:ap-southeast-1:192199979996:model-package/{nim_package}\",\n",
    "    \"ap-southeast-2\": f\"arn:aws:sagemaker:ap-southeast-2:666831318237:model-package/{nim_package}\",\n",
    "    \"ap-northeast-2\": f\"arn:aws:sagemaker:ap-northeast-2:745090734665:model-package/{nim_package}\",\n",
    "    \"ap-northeast-1\": f\"arn:aws:sagemaker:ap-northeast-1:977537786026:model-package/{nim_package}\",\n",
    "    \"ap-south-1\": f\"arn:aws:sagemaker:ap-south-1:077584701553:model-package/{nim_package}\",\n",
    "    \"sa-east-1\": f\"arn:aws:sagemaker:sa-east-1:270155090741:model-package/{nim_package}\",\n",
    "}\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "if region not in model_package_map.keys():\n",
    "    raise Exception(f\"Current boto3 session region {region} is not supported.\")\n",
    "\n",
    "model_package_arn = model_package_map[region]\n",
    "model_package_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8132cd1-6055-4e45-9a92-1e74726ed61b",
   "metadata": {},
   "source": [
    "## Create the SageMaker Endpoint\n",
    "\n",
    "We first define SageMaker model using the specified ModelPackageArn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ee9475-8611-41d1-8c29-5df33f66a1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model details\n",
    "sm_model_name = \"cosmos-reason1-7b\"\n",
    "\n",
    "# Create the SageMaker model\n",
    "create_model_response = sm.create_model(\n",
    "    ModelName=sm_model_name,\n",
    "    PrimaryContainer={\n",
    "        'ModelPackageName': model_package_arn\n",
    "    },\n",
    "    ExecutionRoleArn=role,\n",
    "    EnableNetworkIsolation=True\n",
    ")\n",
    "print(\"Model Arn: \" + create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e096db-0e25-467b-aa9c-18a6a4f1ca60",
   "metadata": {
    "tags": []
   },
   "source": [
    "Next we create endpoint configuration specifying instance type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002bb1b0-d5a6-439d-aa32-01f3fb0953a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the endpoint configuration\n",
    "endpoint_config_name = sm_model_name\n",
    "\n",
    "create_endpoint_config_response = sm.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            'VariantName': 'AllTraffic',\n",
    "            'ModelName': sm_model_name,\n",
    "            'InitialInstanceCount': 1,\n",
    "            'InstanceType': 'ml.g5.12xlarge', \n",
    "            'InferenceAmiVersion': 'al2-ami-sagemaker-inference-gpu-2',\n",
    "            'RoutingConfig': {'RoutingStrategy': 'LEAST_OUTSTANDING_REQUESTS'},\n",
    "            'ModelDataDownloadTimeoutInSeconds': 3600, # Specify the model download timeout in seconds.\n",
    "            'ContainerStartupHealthCheckTimeoutInSeconds': 3600, # Specify the health checkup timeout in seconds\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4065575f-2ad7-438e-a5be-0e80c995414c",
   "metadata": {},
   "source": [
    "Using the above endpoint configuration we create a new sagemaker endpoint and wait for the deployment to finish. The status will change to InService once the deployment is successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28fcac3-4c9d-420e-87fe-7d170b752738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the endpoint\n",
    "endpoint_name = endpoint_config_name\n",
    "create_endpoint_response = sm.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dbe400-99f0-4888-a71e-00259a86fc17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resp = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a97e4c-6dd8-4d9a-841c-e443b7c1583f",
   "metadata": {},
   "source": [
    "### Run Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9146f44-b85c-4125-b842-fceaf5c3cfa8",
   "metadata": {},
   "source": [
    "Once we have the model deployed we can use a sample text to do an inference request. For inference request format, currently NIM on SageMaker supports the OpenAI API inference protocol. For explanation of supported parameters please see [this link](https://docs.api.nvidia.com/nim/reference/nvidia-llama-3_3-nemotron-super-49b-v1-infer)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61480710-ba0f-4e39-8c41-8faaf83cf0a3",
   "metadata": {},
   "source": [
    "#### Non Reasoning Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d106c2",
   "metadata": {},
   "source": [
    "Since Cosmos-Reason1-7B is a VLM (Vision-Language Model), we can run inference with images or videos, and get text response from the model. Additionally, Cosmos-Reason1-7B supports text-only queries. Please refer to docs [text-only-queries](https://docs.nvidia.com/nim/vision-language-models/1.4.1/examples/cosmos-reason1/api.html#text-only-queries)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ac42ec",
   "metadata": {},
   "source": [
    "**Inference with image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bba1ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import mimetypes\n",
    "from pathlib import Path\n",
    "\n",
    "def encode_file_to_base64(file_path):\n",
    "    \"\"\"Encode a local media file to base64 for airgapped environment\"\"\"\n",
    "    file_path = Path(file_path)\n",
    "    \n",
    "    # Guess the MIME type based on the file extension\n",
    "    mime_type, _ = mimetypes.guess_type(file_path)\n",
    "    if mime_type is None:\n",
    "        raise ValueError(f\"Could not determine MIME type for file: {file_path}\")\n",
    "    \n",
    "    with open(file_path, \"rb\") as f:\n",
    "        encoded_string = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "        return f\"data:{mime_type};base64,{encoded_string}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57265e9-98bb-4255-ad7d-143e3aeaf9d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_filename = 'cat.jpg'  # Change to your image file\n",
    "image_data_url = encode_file_to_base64(image_filename)\n",
    "\n",
    "payload_model = \"nvidia/cosmos-reason1-7b\"\n",
    "messages = [\n",
    "    {\n",
    "      \"role\":\"user\",\n",
    "      \"content\":[\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"What is in this image?\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": image_data_url\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "\n",
    "payload = {\n",
    "  \"model\": payload_model,\n",
    "  \"messages\": messages,\n",
    "  \"temperature\": 0.6,\n",
    "  \"max_tokens\": 200\n",
    "}\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, ContentType=\"application/json\", Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "output = json.loads(response[\"Body\"].read().decode(\"utf8\"))\n",
    "print(json.dumps(output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65477640",
   "metadata": {},
   "source": [
    "**Inference with video**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69cfe21",
   "metadata": {},
   "source": [
    "To control how frames are sampled from video inputs, sampling parameters are exposed using the top-level media_io_kwargs API field.\n",
    "\n",
    "Either fps or num_frames can be specified (but not both at the same time). More information please refer to [sampling-and-preprocessing-parameters](https://docs.nvidia.com/nim/vision-language-models/latest/examples/cosmos-reason1/api.html#sampling-and-preprocessing-parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771e4ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_filename = '960_540_25fps.mp4'  # Change to your video file\n",
    "video_data_url = encode_file_to_base64(video_filename)\n",
    "\n",
    "payload_model = \"nvidia/cosmos-reason1-7b\"\n",
    "messages = [\n",
    "    {\n",
    "      \"role\":\"user\",\n",
    "      \"content\":[\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"What is in this video?\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"video_url\",\n",
    "          \"video_url\": {\n",
    "            \"url\": video_data_url\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "\n",
    "payload = {\n",
    "  \"model\": payload_model,\n",
    "  \"messages\": messages,\n",
    "  \"temperature\": 0.6,\n",
    "  \"max_tokens\": 200,\n",
    "  \"media_io_kwargs\": {\"video\": {\"fps\": 1}},\n",
    "}\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, ContentType=\"application/json\", Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "output = json.loads(response[\"Body\"].read().decode(\"utf8\"))\n",
    "print(json.dumps(output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d1bd22-8c19-4a84-81df-c618c5a252e1",
   "metadata": {},
   "source": [
    "#### Reasoning mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7437a0e",
   "metadata": {},
   "source": [
    "Following the [guidance](https://huggingface.co/nvidia/Cosmos-Reason1-7B#input) from model authors, append the following to the system prompt to encourage a long chain-of-thought reasoning response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f3eea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer the question in the following format: <think>\\nyour reasoning\\n</think>\\n\\n<answer>\\nyour answer\\n</answer>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b976b70-c30f-4e5f-96f9-1c7ea24afc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload_model = \"nvidia/cosmos-reason1-7b\"\n",
    "messages = [\n",
    "    {   \n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"Answer the question in the following format: <think>\\nyour reasoning\\n</think>\\n\\n<answer>\\nyour answer\\n</answer>.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\":\"user\",\n",
    "      \"content\":[\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"What is in this image?\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": image_data_url\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "\n",
    "payload = {\n",
    "  \"model\": payload_model,\n",
    "  \"messages\": messages,\n",
    "  \"temperature\": 0.6,\n",
    "  \"max_tokens\": 200\n",
    "}\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, ContentType=\"application/json\", Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "output = json.loads(response[\"Body\"].read().decode(\"utf8\"))\n",
    "print(json.dumps(output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc43d3e-b2ca-4fc5-a434-d109b17814d5",
   "metadata": {},
   "source": [
    "### Streaming inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a94f67-e2fd-45e7-9c2a-014fd3a741af",
   "metadata": {},
   "source": [
    "NIM on SageMaker also supports streaming inference and you can enable that by setting **`\"stream\"` as `True`** in the payload and by using [`invoke_endpoint_with_response_stream`](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker-runtime/client/invoke_endpoint_with_response_stream.html) method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b543e96-7817-44d6-88cb-248a5d6af1e6",
   "metadata": {},
   "source": [
    "#### Non Reasoning Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd5b62a-4405-40d1-8c83-79673a54259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filename = 'cat.jpg'  # Change to your image file\n",
    "image_data_url = encode_file_to_base64(image_filename)\n",
    "\n",
    "payload_model = \"nvidia/cosmos-reason1-7b\"\n",
    "messages = [\n",
    "    {\n",
    "      \"role\":\"user\",\n",
    "      \"content\":[\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"What is in this image?\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": image_data_url\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "\n",
    "payload = {\n",
    "  \"model\": payload_model,\n",
    "  \"messages\": messages,\n",
    "  \"temperature\": 0.6,\n",
    "  \"max_tokens\": 200,\n",
    "  \"stream\": True\n",
    "}\n",
    "\n",
    "response = client.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=json.dumps(payload),\n",
    "    ContentType=\"application/json\",\n",
    "    Accept=\"application/jsonlines\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b443ad-e0af-4a63-887c-2180f25b33b6",
   "metadata": {},
   "source": [
    "We have some postprocessing code for the streaming output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf740626-fb4a-4ab3-8ed3-8f0dfc141530",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_stream = response['Body']\n",
    "accumulated_bytes = b''\n",
    "stream_finished = False # flag to track termination\n",
    "\n",
    "for event in event_stream:\n",
    "    if stream_finished:\n",
    "        break \n",
    "\n",
    "    try:\n",
    "        payload_part = event.get('PayloadPart', {})\n",
    "        if 'Bytes' in payload_part:\n",
    "            accumulated_bytes += payload_part['Bytes']\n",
    "        \n",
    "        decoded_data = accumulated_bytes.decode('utf-8-sig', errors='ignore')\n",
    "    \n",
    "        parts = decoded_data.rpartition('\\n')\n",
    "        lines_to_process = parts[0]\n",
    "        accumulated_bytes = parts[2].encode('utf-8', errors='ignore')\n",
    "        \n",
    "        for line in lines_to_process.split('\\n'):\n",
    "            line = line.strip()\n",
    "            \n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            if line == \"data: [DONE]\":\n",
    "                print(\"\\n\") \n",
    "                stream_finished = True \n",
    "                break\n",
    "            \n",
    "            if line.startswith('data:'):\n",
    "                json_str = line[len('data:'):].strip()\n",
    "                \n",
    "                if json_str:\n",
    "                    try:\n",
    "                        data = json.loads(json_str)\n",
    "                        \n",
    "                        content = data.get('choices', [{}])[0].get('delta', {}).get('content', \"\")\n",
    "                        \n",
    "                        # Print only the generated content token\n",
    "                        if content:\n",
    "                            print(content, end='', flush=True)\n",
    "                            \n",
    "                    except json.JSONDecodeError:\n",
    "                        continue\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n[ERROR: CRITICAL] -> Error processing stream: {e}\", flush=True)\n",
    "        break\n",
    "\n",
    "print(\"\\n[STREAM END: LOOP COMPLETED]\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80433d57-bd36-499b-9da9-c5dde8ca26bc",
   "metadata": {},
   "source": [
    "#### Reasoning mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5abb86-faac-445e-a1c3-0740d1e0fb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload_model = \"nvidia/cosmos-reason1-7b\"\n",
    "messages = [\n",
    "    {   \n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"Answer the question in the following format: <think>\\nyour reasoning\\n</think>\\n\\n<answer>\\nyour answer\\n</answer>.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\":\"user\",\n",
    "      \"content\":[\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"What is in this image?\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": image_data_url\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "\n",
    "payload = {\n",
    "  \"model\": payload_model,\n",
    "  \"messages\": messages,\n",
    "  \"temperature\": 0.6,\n",
    "  \"max_tokens\": 2000,\n",
    "  \"stream\": True\n",
    "}\n",
    "\n",
    "response = client.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=json.dumps(payload),\n",
    "    ContentType=\"application/json\",\n",
    "    Accept=\"application/jsonlines\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8105e1-32b2-407f-a7fc-5aaba75dccc3",
   "metadata": {},
   "source": [
    "We have some postprocessing code for the streaming output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03953ea5-8226-44fa-9d0f-56b8025b4075",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_stream = response['Body']\n",
    "accumulated_bytes = b''\n",
    "stream_finished = False # flag to track termination\n",
    "\n",
    "for event in event_stream:\n",
    "    if stream_finished:\n",
    "        break \n",
    "\n",
    "    try:\n",
    "        payload_part = event.get('PayloadPart', {})\n",
    "        if 'Bytes' in payload_part:\n",
    "            accumulated_bytes += payload_part['Bytes']\n",
    "        \n",
    "        decoded_data = accumulated_bytes.decode('utf-8-sig', errors='ignore')\n",
    "    \n",
    "        parts = decoded_data.rpartition('\\n')\n",
    "        lines_to_process = parts[0]\n",
    "        accumulated_bytes = parts[2].encode('utf-8', errors='ignore')\n",
    "        \n",
    "        for line in lines_to_process.split('\\n'):\n",
    "            line = line.strip()\n",
    "            \n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            if line == \"data: [DONE]\":\n",
    "                print(\"\\n\") \n",
    "                stream_finished = True \n",
    "                break\n",
    "            \n",
    "            if line.startswith('data:'):\n",
    "                json_str = line[len('data:'):].strip()\n",
    "                \n",
    "                if json_str:\n",
    "                    try:\n",
    "                        data = json.loads(json_str)\n",
    "                        \n",
    "                        content = data.get('choices', [{}])[0].get('delta', {}).get('content', \"\")\n",
    "                        \n",
    "                        # Print only the generated content token\n",
    "                        if content:\n",
    "                            print(content, end='', flush=True)\n",
    "                            \n",
    "                    except json.JSONDecodeError:\n",
    "                        continue\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n[ERROR: CRITICAL] -> Error processing stream: {e}\", flush=True)\n",
    "        break\n",
    "\n",
    "print(\"\\n[STREAM END: LOOP COMPLETED]\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19063f6-b6c0-4de2-a193-e482f26f7406",
   "metadata": {},
   "source": [
    "### Terminate endpoint and clean up artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5db083f-4705-4c68-a488-f82da961be4b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm.delete_model(ModelName=sm_model_name)\n",
    "sm.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "sm.delete_endpoint(EndpointName=endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
