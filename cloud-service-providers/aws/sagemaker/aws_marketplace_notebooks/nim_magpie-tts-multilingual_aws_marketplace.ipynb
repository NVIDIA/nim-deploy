{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deploy NVIDIA NIM from AWS Marketplace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NVIDIA NIM, a component of NVIDIA AI Enterprise, enhances your applications with optimized inference microservices for NVIDIA models, delivering a standard API, optimized profiles, and enterprise support."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example we show how to deploy the **Magpie TTS Multilingual** NIM from AWS Marketplace on Amazon SageMaker. Magpie TTS supports text-to-speech synthesis in English (en-US), Spanish (es-US), French (fr-FR), German (de-DE), Mandarin (zh-CN), Vietnamese (vi-VN), and Italian (it-IT)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Please check out the [Magpie TTS model card](https://build.nvidia.com/nvidia/magpie-tts-multilingual/modelcard) and [NIM TTS docs](https://docs.nvidia.com/nim/riva/tts/latest/index.html) for more information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pre-requisites:\n",
        "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
        "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**.\n",
        "1. To deploy this ML model successfully, ensure that:\n",
        "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used:\n",
        "        1. **aws-marketplace:ViewSubscriptions**\n",
        "        1. **aws-marketplace:Unsubscribe**\n",
        "        1. **aws-marketplace:Subscribe**\n",
        "    2. or your AWS account already has a subscription to the model package."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Subscribe to the model package\n",
        "To subscribe to the model package:\n",
        "1. Open the model package listing page\n",
        "1. On the AWS Marketplace listing, click on the **Continue to subscribe** button.\n",
        "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you and your organization agrees with EULA, pricing, and support terms. \n",
        "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn** displayed. This is the model package ARN that you need to specify while creating a deployable model. Copy the ARN corresponding to your region and specify the same in the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import boto3, json, sagemaker, time, os, base64\n",
        "from sagemaker import get_execution_role, ModelPackage\n",
        "from botocore.config import Config\n",
        "\n",
        "config = Config(read_timeout=3600)\n",
        "sess = boto3.Session()\n",
        "sm = sess.client(\"sagemaker\")\n",
        "sagemaker_session = sagemaker.Session(boto_session=sess)\n",
        "role = get_execution_role()\n",
        "client = boto3.client(\"sagemaker-runtime\", config=config)\n",
        "region = sess.region_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Replace the package name below with the AWS Marketplace package name for Magpie TTS Multilingual\n",
        "nim_package = \"\"\n",
        "\n",
        "# Mapping for Model Packages (fill nim_package above, or directly paste full ARNs here)\n",
        "model_package_map = {\n",
        "    \"us-east-1\": f\"arn:aws:sagemaker:us-east-1:865070037744:model-package/{nim_package}\",\n",
        "    \"us-east-2\": f\"arn:aws:sagemaker:us-east-2:057799348421:model-package/{nim_package}\",\n",
        "    \"us-west-1\": f\"arn:aws:sagemaker:us-west-1:382657785993:model-package/{nim_package}\",\n",
        "    \"us-west-2\": f\"arn:aws:sagemaker:us-west-2:594846645681:model-package/{nim_package}\",\n",
        "    \"ca-central-1\": f\"arn:aws:sagemaker:ca-central-1:470592106596:model-package/{nim_package}\",\n",
        "    \"eu-central-1\": f\"arn:aws:sagemaker:eu-central-1:446921602837:model-package/{nim_package}\",\n",
        "    \"eu-west-1\": f\"arn:aws:sagemaker:eu-west-1:985815980388:model-package/{nim_package}\",\n",
        "    \"eu-west-2\": f\"arn:aws:sagemaker:eu-west-2:856760150666:model-package/{nim_package}\",\n",
        "    \"eu-west-3\": f\"arn:aws:sagemaker:eu-west-3:843114510376:model-package/{nim_package}\",\n",
        "    \"eu-north-1\": f\"arn:aws:sagemaker:eu-north-1:136758871317:model-package/{nim_package}\",\n",
        "    \"ap-southeast-1\": f\"arn:aws:sagemaker:ap-southeast-1:192199979996:model-package/{nim_package}\",\n",
        "    \"ap-southeast-2\": f\"arn:aws:sagemaker:ap-southeast-2:666831318237:model-package/{nim_package}\",\n",
        "    \"ap-northeast-2\": f\"arn:aws:sagemaker:ap-northeast-2:745090734665:model-package/{nim_package}\",\n",
        "    \"ap-northeast-1\": f\"arn:aws:sagemaker:ap-northeast-1:977537786026:model-package/{nim_package}\",\n",
        "    \"ap-south-1\": f\"arn:aws:sagemaker:ap-south-1:077584701553:model-package/{nim_package}\",\n",
        "    \"sa-east-1\": f\"arn:aws:sagemaker:sa-east-1:270155090741:model-package/{nim_package}\",\n",
        "}\n",
        "\n",
        "region = boto3.Session().region_name\n",
        "if region not in model_package_map:\n",
        "    raise Exception(f\"Current boto3 session region {region} is not supported.\")\n",
        "\n",
        "model_package_arn = model_package_map[region]\n",
        "model_package_arn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the SageMaker Endpoint\n",
        "\n",
        "We first define a SageMaker model using the specified `ModelPackageArn`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the model details\n",
        "sm_model_name = \"magpie-tts-multilingual\"\n",
        "\n",
        "create_model_response = sm.create_model(\n",
        "    ModelName=sm_model_name,\n",
        "    PrimaryContainer={\n",
        "        \"ModelPackageName\": model_package_arn\n",
        "    },\n",
        "    ExecutionRoleArn=role,\n",
        "    EnableNetworkIsolation=True,\n",
        ")\n",
        "print(\"Model Arn: \" + create_model_response[\"ModelArn\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next we create an endpoint configuration specifying instance type. Recommended starting point: `ml.g6e.xlarge`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "endpoint_config_name = sm_model_name\n",
        "\n",
        "create_endpoint_config_response = sm.create_endpoint_config(\n",
        "    EndpointConfigName=endpoint_config_name,\n",
        "    ProductionVariants=[\n",
        "        {\n",
        "            \"VariantName\": \"AllTraffic\",\n",
        "            \"ModelName\": sm_model_name,\n",
        "            \"InitialInstanceCount\": 1,\n",
        "            \"InstanceType\": \"ml.g6e.xlarge\",\n",
        "            \"InferenceAmiVersion\": \"al2-ami-sagemaker-inference-gpu-2\",\n",
        "            \"RoutingConfig\": {\"RoutingStrategy\": \"LEAST_OUTSTANDING_REQUESTS\"},\n",
        "            \"ModelDataDownloadTimeoutInSeconds\": 3600,\n",
        "            \"ContainerStartupHealthCheckTimeoutInSeconds\": 3600,\n",
        "        }\n",
        "    ],\n",
        ")\n",
        "print(\"Endpoint Config Arn: \" + create_endpoint_config_response[\"EndpointConfigArn\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create an endpoint and wait for it to become `InService`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "endpoint_name = endpoint_config_name\n",
        "create_endpoint_response = sm.create_endpoint(\n",
        "    EndpointName=endpoint_name,\n",
        "    EndpointConfigName=endpoint_config_name,\n",
        ")\n",
        "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resp = sm.describe_endpoint(EndpointName=endpoint_name)\n",
        "status = resp[\"EndpointStatus\"]\n",
        "print(\"Status: \" + status)\n",
        "\n",
        "while status == \"Creating\":\n",
        "    time.sleep(60)\n",
        "    resp = sm.describe_endpoint(EndpointName=endpoint_name)\n",
        "    status = resp[\"EndpointStatus\"]\n",
        "    print(\"Status: \" + status)\n",
        "\n",
        "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
        "print(\"Status: \" + status)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### API Request Format\n",
        "\n",
        "The request body follows the [NVIDIA Riva TTS SynthesizeSpeechRequest proto](https://docs.nvidia.com/nim/riva/tts/1.6.0/protos.html#nvidia-riva-tts-synthesizespeechrequest):\n",
        "\n",
        "| Field | Type | Required | Description |\n",
        "|-------|------|----------|-------------|\n",
        "| `text` | string | ✅ Yes | Text to synthesize |\n",
        "| `voice_name` | string | No | Voice name ([available voices](https://docs.nvidia.com/nim/riva/tts/1.10.0/support-matrix.html#available-voices)) |\n",
        "| `language_code` | string | No | Language code: en-US, es-US, fr-FR, de-DE, zh-CN, vi-VN, it-IT ([docs](https://docs.nvidia.com/nim/riva/tts/1.10.0/support-matrix.html#magpie-tts-multilingual)) |\n",
        "| `sample_rate_hz` | int | No | Sample rate (default: 44100) |\n",
        "| `encoding` | string | No | `LINEAR_PCM` or `OGGOPUS` |\n",
        "| `zero_shot_data` | object | No | `{audio_prompt, quality, transcript}` for voice cloning (gRPC only) |\n",
        "| `custom_dictionary` | string | No | `\"word1  pron1,word2  pron2\"` with double-space separator (gRPC only) |\n",
        "\n",
        "### Response Format\n",
        "\n",
        "Response matches [NIM SynthesizeSpeechResponse](https://docs.nvidia.com/nim/riva/tts/1.6.0/protos.html#nvidia-riva-tts-synthesizespeechresponse):\n",
        "\n",
        "| Field | Type | Description |\n",
        "|-------|------|-------------|\n",
        "| `audio` | string | Base64-encoded audio bytes |\n",
        "| `meta` | object | Optional metadata from NIM |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Non-Streaming Request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "payload = {\n",
        "    \"text\": \"Hello, this is a Magpie TTS AWS Marketplace test.\",\n",
        "    \"language_code\": \"en-US\",\n",
        "    \"voice_name\": \"Magpie-Multilingual.EN-US.Aria\",\n",
        "    \"sample_rate_hz\": 44100,\n",
        "    \"encoding\": \"LINEAR_PCM\",\n",
        "}\n",
        "\n",
        "response = client.invoke_endpoint(\n",
        "    EndpointName=endpoint_name,\n",
        "    Body=json.dumps(payload),\n",
        "    ContentType=\"application/json\",\n",
        "    Accept=\"application/json\",\n",
        ")\n",
        "\n",
        "out = json.loads(response[\"Body\"].read().decode(\"utf8\"))\n",
        "audio_bytes = base64.b64decode(out[\"audio\"])\n",
        "with open(\"magpie_marketplace.wav\", \"wb\") as f:\n",
        "    f.write(audio_bytes)\n",
        "print(\"Wrote magpie_marketplace.wav\", len(audio_bytes), \"bytes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Transport Selection (Optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use `CustomAttributes` header to select HTTP or gRPC transport:\n",
        "\n",
        "| CustomAttributes | Description |\n",
        "|------------------|-------------|\n",
        "| `/invocations/http` | Force HTTP transport |\n",
        "| `/invocations/grpc` | Force gRPC transport |\n",
        "| *(not set)* | Auto-routing |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "payload = {\n",
        "    \"text\": \"This request forces gRPC transport.\",\n",
        "    \"language_code\": \"en-US\",\n",
        "    \"voice_name\": \"Magpie-Multilingual.EN-US.Aria\",\n",
        "    \"sample_rate_hz\": 44100,\n",
        "    \"encoding\": \"LINEAR_PCM\",\n",
        "}\n",
        "\n",
        "print(\"Sending TTS request forcing gRPC transport...\")\n",
        "\n",
        "response = client.invoke_endpoint(\n",
        "    EndpointName=endpoint_name,\n",
        "    Body=json.dumps(payload),\n",
        "    ContentType=\"application/json\",\n",
        "    Accept=\"application/json\",\n",
        "    CustomAttributes=\"/invocations/grpc\",\n",
        ")\n",
        "\n",
        "out = json.loads(response[\"Body\"].read().decode(\"utf8\"))\n",
        "\n",
        "if \"audio\" in output:\n",
        "    audio_bytes = base64.b64decode(output[\"audio\"])\n",
        "    with open(\"output_forced_grpc.wav\", \"wb\") as f:\n",
        "        f.write(audio_bytes)\n",
        "    print(f\"Audio saved to output_forced_grpc.wav ({len(audio_bytes)} bytes)\")\n",
        "else:\n",
        "    print(\"No 'audio' key in response:\", output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TTS with Custom Dictionary (gRPC-only)\n",
        "Use custom pronunciation dictionary for specific words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "payload = {\n",
        "    \"text\": \"Welcome to NVIDIA and Amazon SageMaker integration.\",\n",
        "    \"language_code\": \"en-US\",\n",
        "    \"voice_name\": \"Magpie-Multilingual.EN-US.Aria\",\n",
        "    \"custom_dictionary\": \"NVIDIA  en-VID-ee-ah,SageMaker  SAGE-may-ker,TTS  tee-tee-ess\",\n",
        "    \"sample_rate_hz\": 44100\n",
        "}\n",
        "\n",
        "print(\"Sending TTS request with custom dictionary...\")\n",
        "\n",
        "response = client.invoke_endpoint(\n",
        "    EndpointName=endpoint_name,\n",
        "    Body=json.dumps(payload),\n",
        "    ContentType=\"application/json\",\n",
        "    Accept=\"application/json\"\n",
        ")\n",
        "\n",
        "output = json.loads(response[\"Body\"].read().decode(\"utf8\"))\n",
        "\n",
        "if 'audio' in output:\n",
        "    audio_b64 = output['audio']\n",
        "    audio_bytes = base64.b64decode(audio_b64)\n",
        "    \n",
        "    with open('output_custom_dict.wav', 'wb') as f:\n",
        "        f.write(audio_bytes)\n",
        "    \n",
        "    print(f\"Audio saved to output_custom_dict.wav ({len(audio_bytes)} bytes)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Streaming inference\n",
        "\n",
        "Use `invoke_endpoint_with_response_stream` and `CustomAttributes=\"/invocations/stream\"`.\n",
        "\n",
        "This returns raw audio chunks which you can write to a file and optionally convert to WAV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "payload = {\n",
        "    \"text\": \"This is a streaming text-to-speech example. Audio is delivered in real-time.\",\n",
        "    \"language_code\": \"en-US\",\n",
        "    \"voice_name\": \"Magpie-Multilingual.EN-US.Aria\",\n",
        "    \"sample_rate_hz\": 44100\n",
        "}\n",
        "\n",
        "print(\"Sending streaming TTS request...\")\n",
        "\n",
        "stream_resp = client.invoke_endpoint_with_response_stream(\n",
        "    EndpointName=endpoint_name,\n",
        "    Body=json.dumps(payload),\n",
        "    ContentType=\"application/json\",\n",
        "    CustomAttributes=\"/invocations/stream\",\n",
        ")\n",
        "\n",
        "event_stream = stream_resp['Body']\n",
        "audio_chunks = []\n",
        "chunk_count = 0\n",
        "\n",
        "for event in event_stream:\n",
        "    try:\n",
        "        payload_part = event.get('PayloadPart', {})\n",
        "        if 'Bytes' in payload_part:\n",
        "            chunk = payload_part['Bytes']\n",
        "            audio_chunks.append(chunk)\n",
        "            chunk_count += 1\n",
        "            if chunk_count == 1:\n",
        "                print(f\"First audio chunk received! ({len(chunk)} bytes)\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing stream: {e}\")\n",
        "        break\n",
        "\n",
        "if audio_chunks:\n",
        "    audio_data = b''.join(audio_chunks)\n",
        "    \n",
        "    with open('output_streaming.raw', 'wb') as f:\n",
        "        f.write(audio_data)\n",
        "    \n",
        "    print(f\"Streaming complete: {chunk_count} chunks, {len(audio_data)} bytes total\")\n",
        "    print(f\"Raw audio saved to output_streaming.raw\")\n",
        "    \n",
        "    import wave, io\n",
        "    wav_buffer = io.BytesIO()\n",
        "    with wave.open(wav_buffer, 'wb') as wav_file:\n",
        "        wav_file.setnchannels(1)\n",
        "        wav_file.setsampwidth(2)\n",
        "        wav_file.setframerate(44100)\n",
        "        wav_file.writeframesraw(audio_data)\n",
        "    \n",
        "    with open('output_streaming.wav', 'wb') as f:\n",
        "        f.write(wav_buffer.getvalue())\n",
        "    \n",
        "    print(f\"WAV audio saved to output_streaming.wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Multilingual Examples\n",
        "Supported languages: en-US, es-US, fr-FR, de-DE, zh-CN, vi-VN, it-IT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Spanish example\n",
        "payload_spanish = {\n",
        "    \"text\": \"Hola, bienvenido a NVIDIA.\",\n",
        "    \"language_code\": \"es-US\",\n",
        "    \"sample_rate_hz\": 44100\n",
        "}\n",
        "\n",
        "response = client.invoke_endpoint(\n",
        "    EndpointName=endpoint_name,\n",
        "    Body=json.dumps(payload_spanish),\n",
        "    ContentType=\"application/json\",\n",
        "    Accept=\"application/json\"\n",
        ")\n",
        "\n",
        "output = json.loads(response[\"Body\"].read().decode(\"utf8\"))\n",
        "if 'audio' in output:\n",
        "    with open('output_spanish.wav', 'wb') as f:\n",
        "        f.write(base64.b64decode(output['audio']))\n",
        "    print(\"Spanish audio saved\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cleanup\n",
        "\n",
        "Delete resources when you’re done to avoid ongoing charges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sm.delete_model(ModelName=sm_model_name)\n",
        "# sm.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
        "# sm.delete_endpoint(EndpointName=endpoint_name)\n",
        "print(\"Cleanup cells ready (commented out)\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
