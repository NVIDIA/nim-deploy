apiVersion: run.ai/v2alpha1
kind: InferenceWorkload
metadata:
  name: basic-llama-pvc
  namespace: {{ .Values.namespace }}
spec:
  name:
    value: basic-llama-pvc
  environment:
    items:
      NGC_API_KEY:
        value: SECRET:ngc-secret-pvc,NGC_API_KEY
  gpu:
    value: "1"
  image:
    value: "nvcr.io/nim/meta/llama-3.1-8b-instruct"
  minScale:
    value: 1
  maxScale:
    value: 2
  runAsUid:
    value: 1000
  runAsGid:
    value: 1000
  ports:
    items:
      serving-port:
        value:
          container: 8000
          protocol: http
          serviceType: ServingPort
  pvcs:
    items:
      pvc:
        value:
          claimName: nim-cache
          existingPvc: true
          path: /opt/nim/.cache
          readOnly: false
